{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT5BL9nf73Yu",
        "outputId": "f0396722-8b21-4843-d219-c3611c363660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting azure-storage-blob\n",
            "  Downloading azure_storage_blob-12.25.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (2.2.3)\n",
            "Collecting azure-core>=1.30.0 (from azure-storage-blob)\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting cryptography>=2.1.4 (from azure-storage-blob)\n",
            "  Downloading cryptography-44.0.2-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from azure-storage-blob) (4.11.0)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from pandas) (1.26.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
            "Downloading azure_storage_blob-12.25.0-py3-none-any.whl (406 kB)\n",
            "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "Downloading cryptography-44.0.2-cp39-abi3-macosx_10_9_universal2.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, cryptography, azure-core, azure-storage-blob\n",
            "Successfully installed azure-core-1.32.0 azure-storage-blob-12.25.0 cryptography-44.0.2 isodate-0.7.2\n"
          ]
        }
      ],
      "source": [
        "! pip install azure-storage-blob requests pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgO-3_DDtKM-"
      },
      "outputs": [],
      "source": [
        "import requests as req\n",
        "import pandas as pd\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "import os\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "ZQOLKA6O788v"
      },
      "outputs": [],
      "source": [
        "connection_string = os.getenv('AZURE_CONNECTION_STRING')\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "YMn_TXVu-JRG"
      },
      "outputs": [],
      "source": [
        "def upload_blob(blob_service_client, blob_name, local_file_path):\n",
        "  container_name = \"bdmcontainerp1\"\n",
        "  container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "  with open(local_file_path, \"rb\") as data:\n",
        "      container_client.upload_blob(name=blob_name, data=data, overwrite=True)\n",
        "\n",
        "  blobs = [blob.name for blob in container_client.list_blobs()]\n",
        "  if blob_name not in blobs:\n",
        "    raise Exception(\"Blob was not uploaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Landing Zone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL-P6vyqqybN"
      },
      "source": [
        "## Weather Data\n",
        "Check for more examples:  https://open-meteo.com/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error al obtener datos para Rome el 2024-03-30: 504 Server Error: Gateway Time-out for url: https://archive-api.open-meteo.com/v1/archive?latitude=41.8967&longitude=12.4822&hourly=temperature_2m%2Crain%2Csnowfall%2Cprecipitation%2Ccloud_cover%2Cwind_speed_10m%2Csunshine_duration&start_date=2024-03-30&end_date=2024-03-30&timezone=auto\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import requests as req\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def save_json_response(city, date_str, data, directory=\"weather\"):\n",
        "    city_dir = os.path.join(directory, city)\n",
        "    os.makedirs(city_dir, exist_ok=True)\n",
        "    \n",
        "    file_path = os.path.join(city_dir, f\"{date_str}.json\")\n",
        "    \n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "\n",
        "start_date = datetime.strptime('2024-03-24', '%Y-%m-%d')\n",
        "end_date = datetime.strptime('2024-06-25', '%Y-%m-%d')\n",
        "\n",
        "city_coords = {\n",
        "    'Barcelona': {'latitude': 41.3874, 'longitude': 2.1686},\n",
        "    'Paris': {'latitude': 48.8575, 'longitude': 2.3514},\n",
        "    'Madrid': {'latitude': 40.4167, 'longitude': -3.7033},\n",
        "    'Rome': {'latitude': 41.8967, 'longitude': 12.4822}\n",
        "}\n",
        "\n",
        "hourly = 'temperature_2m,rain,snowfall,precipitation,cloud_cover,wind_speed_10m,sunshine_duration'\n",
        "weather_endpoint = 'https://archive-api.open-meteo.com/v1/archive'\n",
        "\n",
        "# Loop por fecha\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    next_date = current_date + timedelta(days=1)\n",
        "\n",
        "    current_date_str = current_date.strftime('%Y-%m-%d')\n",
        "    next_date_str = next_date.strftime('%Y-%m-%d')\n",
        "\n",
        "    for city, coords in city_coords.items():\n",
        "        latitude = coords['latitude']\n",
        "        longitude = coords['longitude']\n",
        "\n",
        "        querystring = {\n",
        "            'latitude': latitude,\n",
        "            'longitude': longitude,\n",
        "            'hourly': hourly,\n",
        "            'start_date': current_date_str,\n",
        "            'end_date': current_date_str,\n",
        "            'timezone': 'auto'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = req.get(weather_endpoint, params=querystring)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            save_json_response(city, current_date_str, data)\n",
        "        except Exception as e:\n",
        "            print(f\"Error al obtener datos para {city} el {current_date_str}: {e}\")\n",
        "\n",
        "    current_date = next_date\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ki9cZcII2E1d",
        "outputId": "24216c9a-bb02-4496-d19c-318f32d4c8c1"
      },
      "outputs": [],
      "source": [
        "latitude = 41.8967\n",
        "longitude = 12.4822\n",
        "city_coords = {\n",
        "                'Barcelona': {'latitude': 41.3874, 'longitude': 2.1686},\n",
        "                'Paris': {'latitude': 48.8575, 'longitude': 2.3514},\n",
        "                'Madrid': {'latitude': 40.4167, 'longitude': 3.7033},\n",
        "                'Rome': {'latitude': 41.8967, 'longitude': 12.4822}\n",
        "                }\n",
        "\n",
        "start_date = '2024-03-30'\n",
        "end_date = '2024-03-30'\n",
        "hourly = 'temperature_2m,rain,snowfall,precipitation,cloud_cover,wind_speed_10m,sunshine_duration'\n",
        "querystring = {\n",
        "                'latitude':latitude,\n",
        "                'longitude':longitude,\n",
        "                'hourly':hourly,\n",
        "                'start_date':start_date,\n",
        "                'end_date':end_date\n",
        "                }\n",
        "\n",
        "weather_endpoint = f'https://archive-api.open-meteo.com/v1/archive'\n",
        "weather_res = req.get(weather_endpoint, params=querystring).json()\n",
        "save_json_response('Rome', start_date, weather_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ-WdmD5q04J"
      },
      "source": [
        "## Accomodation Data\n",
        "\n",
        "Check for more examples: https://rapidapi.com/DataCrawler/api/booking-com15/playground/apiendpoint_818c2744-8507-4071-829e-d080b667a06c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxO6GyDJ4J5h",
        "outputId": "3401172b-fa23-4ef9-e605-05d1cbf40350"
      },
      "outputs": [],
      "source": [
        "def save_images(res, client, querystring, city):\n",
        "    hotels = res['data']['hotels']\n",
        "    for hotel in hotels:\n",
        "        photos = hotel['property']['photoUrls']\n",
        "        for photo in photos:\n",
        "            img_res = req.get(photo, stream=True)\n",
        "            filename = city + '/' + str(hotel['hotel_id']) + '_' + querystring['dest_id'] + '_' + querystring['arrival_date'] + '_' + querystring['departure_date'] + '.jpg'\n",
        "            if img_res.status_code == 200:\n",
        "                with open('accomodation_images/' + filename, \"wb\") as file:\n",
        "                    for chunk in img_res.iter_content(1024):  # Guardar en bloques de 1024 bytes\n",
        "                        file.write(chunk)\n",
        "            upload_blob(client, f'accomodation_images/{filename}', f'accomodation_images/{filename}')\n",
        "            os.remove(f'accomodation_images/{filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_json(res, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(res, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/218 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Paris\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/218 [14:33<52:38:21, 873.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barcelona\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Paris\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 2/218 [32:57<60:33:24, 1009.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barcelona\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Paris\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 3/218 [51:32<63:09:50, 1057.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barcelona\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Paris\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 4/218 [2:01:49<137:00:32, 2304.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barcelona\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Paris\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 5/218 [2:24:50<116:39:06, 1971.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barcelona\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Paris\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 6/218 [2:53:29<111:02:21, 1885.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barcelona\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Paris\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 7/218 [3:15:23<99:34:10, 1698.82s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barcelona\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Rome\n",
            "Accomodation data retrieved successfully\n",
            "Weather data retrieved successfully\n",
            "Madrid\n",
            "Accomodation data retrieved successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 7/218 [12:54:35<389:08:14, 6639.31s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccomodation data retrieved successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m accomodation_res \u001b[38;5;241m=\u001b[39m accomodation_res\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m---> 71\u001b[0m save_images(accomodation_res, blob_service_client, accomodation_querystring, city)\n\u001b[1;32m     72\u001b[0m json_res_filename \u001b[38;5;241m=\u001b[39m  city \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m accomodation_querystring[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrival_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m accomodation_querystring[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeparture_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     73\u001b[0m save_json(accomodation_res, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccomodation/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_res_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36msave_images\u001b[0;34m(res, client, querystring, city)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img_res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccomodation_images/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m img_res\u001b[38;5;241m.\u001b[39miter_content(\u001b[38;5;241m1024\u001b[39m):  \u001b[38;5;66;03m# Guardar en bloques de 1024 bytes\u001b[39;00m\n\u001b[1;32m     11\u001b[0m             file\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     12\u001b[0m upload_blob(client, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccomodation_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccomodation_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages/urllib3/response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages/urllib3/response.py:1209\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_chunk(amt)\n\u001b[1;32m   1210\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[1;32m   1211\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m )\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/site-packages/urllib3/response.py:1146\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left:\n\u001b[0;32m-> 1146\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(amt)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m-\u001b[39m amt\n\u001b[1;32m   1148\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/http/client.py:640\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/tpc-di/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "accomodation_endpoint = \"https://booking-com15.p.rapidapi.com/api/v1/hotels/searchHotels\"\n",
        "weather_endpoint = f'https://api.open-meteo.com/v1/forecast'\n",
        "\n",
        "delta = timedelta(days=1)\n",
        "\n",
        "destination_ids = {\n",
        "    \"Barcelona\": \"-372490\",\n",
        "    \"Rome\": \"-126693\",\n",
        "    \"Madrid\": \"-390625\",\n",
        "    \"Paris\": \"-1456928\"\n",
        "}\n",
        "\n",
        "headers = {\n",
        "            \"x-rapidapi-key\": os.environ[\"RAPID_API_KEY\"],\n",
        "            \"x-rapidapi-host\": os.environ[\"RAPID_API_HOST\"]\n",
        "        }\n",
        "\n",
        "accomodation_querystring = {\n",
        "            \"dest_id\": '',\n",
        "            \"search_type\": \"CITY\",\n",
        "            \"arrival_date\": '',\n",
        "            \"departure_date\": '',\n",
        "            \"adults\": \"2\",\n",
        "            \"children_age\": \"0\",\n",
        "            \"room_qty\": \"1\",\n",
        "            \"page_number\": \"1\",\n",
        "            \"units\": \"metric\",\n",
        "            \"temperature_unit\": \"c\",\n",
        "            \"languagecode\": \"en-us\",\n",
        "            \"currency_code\": \"EUR\"\n",
        "        }\n",
        "\n",
        "destination_coords = {\n",
        "                'Barcelona': {'latitude': 41.3874, 'longitude': 2.1686},\n",
        "                'Paris': {'latitude': 48.8575, 'longitude': 2.3514},\n",
        "                'Madrid': {'latitude': 40.4167, 'longitude': 3.7033},\n",
        "                'Rome': {'latitude': 41.8967, 'longitude': 12.4822}\n",
        "                }\n",
        "\n",
        "weather_metrics = 'temperature_2m,precipitation_probability,apparent_temperature,precipitation,cloud_cover,wind_speed_10m'\n",
        "weather_querystring = {\n",
        "                'latitude': '',\n",
        "                'longitude': '',\n",
        "                'hourly': weather_metrics,\n",
        "                'start_date': '',\n",
        "                'end_date': ''\n",
        "                }\n",
        "\n",
        "start = datetime.strptime('2025-06-05', \"%Y-%m-%d\")\n",
        "end = datetime.strptime('2025-06-10', \"%Y-%m-%d\")\n",
        "last_city = 'Rome'\n",
        "try:\n",
        "    for single_date in tqdm([start + i * delta for i in range((end - start).days + 1)]):\n",
        "        arrival_date = single_date.strftime(\"%Y-%m-%d\")\n",
        "        departure_date = (single_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        start_date = single_date.replace(year=single_date.year - 1).strftime(\"%Y-%m-%d\")\n",
        "        end_date = (single_date + timedelta(days=1)).replace(year=single_date.year - 1).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        for city, city_id in destination_ids.items():\n",
        "            if last_city and city != last_city:\n",
        "                continue\n",
        "            print(city)\n",
        "            accomodation_querystring['dest_id'] = city_id\n",
        "            accomodation_querystring['arrival_date'] = arrival_date\n",
        "            accomodation_querystring['departure_date'] = departure_date\n",
        "            \n",
        "            accomodation_res = req.get(accomodation_endpoint, headers=headers, params=accomodation_querystring)\n",
        "            if accomodation_res.status_code == 200:\n",
        "                print(\"Accomodation data retrieved successfully\")\n",
        "                accomodation_res = accomodation_res.json()\n",
        "                save_images(accomodation_res, blob_service_client, accomodation_querystring, city)\n",
        "                json_res_filename =  city + '/' + accomodation_querystring['arrival_date'] + '_' + accomodation_querystring['departure_date'] + '.json'\n",
        "                save_json(accomodation_res, f'accomodation/{json_res_filename}')\n",
        "                upload_blob(blob_service_client, f'accomodation/{json_res_filename}', f'accomodation/{json_res_filename}')\n",
        "                os.remove(f'accomodation/{json_res_filename}')\n",
        "            else:\n",
        "                print('Accomodation', city, arrival_date, departure_date, accomodation_res)\n",
        "                last_city = city\n",
        "                raise\n",
        "\n",
        "            latitude, longitude = destination_coords[city].values()\n",
        "            weather_querystring['latitude'] = latitude\n",
        "            weather_querystring['longitude'] = longitude\n",
        "            weather_querystring['start_date'] = start_date\n",
        "            weather_querystring['end_date'] = start_date\n",
        "            weather_json_filename = city + '/' + start_date + '.json'\n",
        "            \n",
        "            weather_res = req.get(weather_endpoint, params=weather_querystring)\n",
        "            if weather_res.status_code == 200:\n",
        "                print(\"Weather data retrieved successfully\")\n",
        "                weather_res = weather_res.json()\n",
        "                save_json(weather_res, f'weather/{weather_json_filename}')\n",
        "                upload_blob(blob_service_client, f'weather/{weather_json_filename}', f'weather/{weather_json_filename}')\n",
        "                os.remove(f'weather/{weather_json_filename}')\n",
        "            else:\n",
        "                print('Weather', city, start_date, end_date, weather_res)\n",
        "                last_city = city\n",
        "                raise\n",
        "            \n",
        "            if last_city:\n",
        "                last_city = None\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(last_city, arrival_date, departure_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "container_name = \"bdmcontainerp1\"\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "metadata_list = []\n",
        "\n",
        "for blob in container_client.list_blobs():\n",
        "    blob_client = container_client.get_blob_client(blob.name)\n",
        "    blob_properties = blob_client.get_blob_properties()\n",
        "\n",
        "    metadata_list.append({\n",
        "        \"blob_name\": blob.name,\n",
        "        \"size\": blob.size,\n",
        "        \"last_modified\": blob.last_modified.isoformat() if blob.last_modified else None,\n",
        "        \"creation_time\": getattr(blob_properties, \"creation_time\", None),\n",
        "        \"etag\": blob.etag,\n",
        "        \"content_type\": blob_properties.content_settings.content_type,\n",
        "        \"content_encoding\": blob_properties.content_settings.content_encoding,\n",
        "        \"content_language\": blob_properties.content_settings.content_language,\n",
        "        \"content_disposition\": blob_properties.content_settings.content_disposition,\n",
        "        \"cache_control\": blob_properties.content_settings.cache_control,\n",
        "        \"lease_status\": getattr(blob_properties.lease, \"status\", None),\n",
        "        \"lease_state\": getattr(blob_properties.lease, \"state\", None),\n",
        "        \"lease_duration\": getattr(blob_properties.lease, \"duration\", None),\n",
        "        \"access_tier\": getattr(blob_properties, \"blob_tier\", None),\n",
        "        \"access_tier_inferred\": getattr(blob_properties, \"blob_tier_inferred\", None),\n",
        "        \"access_tier_last_modified\": getattr(blob_properties, \"blob_tier_last_modified\", None),\n",
        "        \"server_encrypted\": getattr(blob_properties, \"server_encrypted\", None),\n",
        "        \"encryption_key_sha256\": getattr(blob_properties, \"encryption_key_sha256\", None),\n",
        "        \"customer_provided_key_sha256\": getattr(blob_properties, \"customer_provided_key_sha256\", None),\n",
        "        \"tags\": blob_properties.tags if blob_properties.tags else None,\n",
        "        \"snapshot\": getattr(blob, \"snapshot\", None),\n",
        "        \"version_id\": getattr(blob, \"version_id\", None),\n",
        "        \"is_current_version\": getattr(blob, \"is_current_version\", None),\n",
        "        \"rehydration_status\": getattr(blob_properties, \"rehydration_status\", None),\n",
        "        \"metadata\": blob_properties.metadata\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'blob_name': 'accomodation/Barcelona/2025-03-24_2025-03-25.json',\n",
              " 'size': 39155,\n",
              " 'last_modified': '2025-03-24T20:18:11+00:00',\n",
              " 'creation_time': datetime.datetime(2025, 3, 24, 20, 18, 11, tzinfo=datetime.timezone.utc),\n",
              " 'etag': '0x8DD6B10FFBCDD81',\n",
              " 'content_type': 'application/octet-stream',\n",
              " 'content_encoding': None,\n",
              " 'content_language': None,\n",
              " 'content_disposition': None,\n",
              " 'cache_control': None,\n",
              " 'lease_status': 'unlocked',\n",
              " 'lease_state': 'available',\n",
              " 'lease_duration': None,\n",
              " 'access_tier': 'Hot',\n",
              " 'access_tier_inferred': True,\n",
              " 'access_tier_last_modified': None,\n",
              " 'server_encrypted': True,\n",
              " 'encryption_key_sha256': None,\n",
              " 'customer_provided_key_sha256': None,\n",
              " 'tags': None,\n",
              " 'snapshot': None,\n",
              " 'version_id': None,\n",
              " 'is_current_version': None,\n",
              " 'rehydration_status': None,\n",
              " 'metadata': {}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metadata_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_filename = \"blob_metadata.json\"\n",
        "with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(metadata_list, json_file, indent=4)\n",
        "\n",
        "print(f\"Metadata stored in {json_filename}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trusted Zone\n",
        "The following transformations will be done to the data:\n",
        "* Schema flattening: En columna de price por ejemplo\n",
        "* Schema correction: Hacer una propuesta de esquema e imponerlo en todos los documentos (esquema + data types)\n",
        "\n",
        "* Compress images\n",
        "* Check file integrity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "container_name = \"bdmcontainerp1\"\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "blobs = [blob for blob in container_client.list_blobs()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accomodation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Access the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for blob in blobs:\n",
        "    if \"accomodation/\" in blob.name and \"json\" in blob.name:\n",
        "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob.name)\n",
        "        blob_data = blob_client.download_blob()\n",
        "        content = blob_data.readall().decode('utf-8')\n",
        "        data = json.loads(content)\n",
        "        with open(blob.name, \"w\") as file:\n",
        "            json.dump(data, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Data Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten_dict(d, parent_key='', sep='_'):\n",
        "    items = {}\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "        if isinstance(v, dict):\n",
        "            items.update(flatten_dict(v, new_key, sep=sep))\n",
        "        else:\n",
        "            items[new_key] = v\n",
        "    return items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Schema Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_schema(d, indent=0):\n",
        "    schema = {}\n",
        "    for key, value in d.items():\n",
        "        if isinstance(value, dict):\n",
        "            schema[key] = get_schema(value, indent + 2)\n",
        "        elif isinstance(value, list):\n",
        "            if len(value) > 0 and isinstance(value[0], dict):\n",
        "                schema[key] = [get_schema(value[0], indent + 2)]\n",
        "            else:\n",
        "                schema[key] = [type(value[0]).__name__ if value else \"unknown\"]\n",
        "        else:\n",
        "            schema[key] = type(value).__name__\n",
        "    return schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Schema Enforcement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enforce_schema(data, schema):\n",
        "    def cast_value(value, expected_type):\n",
        "        try:\n",
        "            if expected_type == \"int\":\n",
        "                return int(value)\n",
        "            elif expected_type == \"float\":\n",
        "                return float(value)\n",
        "            elif expected_type == \"str\":\n",
        "                return str(value)\n",
        "            elif expected_type == \"bool\":\n",
        "                if isinstance(value, str):\n",
        "                    return value.lower() in [\"true\", \"1\", \"yes\"]\n",
        "                return bool(value)\n",
        "            else:\n",
        "                return None\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def enforce(data, schema):\n",
        "        if not isinstance(data, dict):\n",
        "            return {}\n",
        "\n",
        "        for key, expected in schema.items():\n",
        "            if key not in data:\n",
        "                data[key] = None\n",
        "            else:\n",
        "                if isinstance(expected, dict):\n",
        "                    if not isinstance(data[key], dict):\n",
        "                        data[key] = {}\n",
        "                    data[key] = enforce(data[key], expected)\n",
        "                elif isinstance(expected, list) and expected and isinstance(expected[0], dict):\n",
        "                    if not isinstance(data[key], list):\n",
        "                        data[key] = []\n",
        "                    else:\n",
        "                        data[key] = [enforce(item, expected[0]) if isinstance(item, dict) else {} for item in data[key]]\n",
        "                elif isinstance(expected, list):\n",
        "                    # Primitive lists (e.g., [\"int\"])\n",
        "                    if not isinstance(data[key], list):\n",
        "                        data[key] = []\n",
        "                    else:\n",
        "                        data[key] = [cast_value(item, expected[0]) for item in data[key]]\n",
        "                else:\n",
        "                    # Primitive value\n",
        "                    data[key] = cast_value(data[key], expected)\n",
        "        return data\n",
        "\n",
        "    return enforce(data.copy(), schema)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Running the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 83.46it/s] \n",
            "100%|██████████| 90/90 [00:00<00:00, 127.43it/s]\n",
            "100%|██████████| 92/92 [00:00<00:00, 155.09it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 132.59it/s]\n"
          ]
        }
      ],
      "source": [
        "with open(\"accomodation_schema.json\", \"r\") as file:\n",
        "    accomodation_schema = json.load(file)\n",
        "\n",
        "cities = ['Barcelona', \"Paris\", 'Rome', 'Madrid']\n",
        "\n",
        "for city in cities:\n",
        "    for file_name in tqdm(os.listdir(f'accomodation/{city}/')):\n",
        "        documents = []\n",
        "        path = f'accomodation/{city}/{file_name}'\n",
        "        with open(path, \"r\") as file:\n",
        "            data = json.load(file)\n",
        "        file = data['data']['hotels']\n",
        "        for doc in file:\n",
        "            flattened = flatten_dict(doc)\n",
        "            schema = get_schema(flattened)\n",
        "            standardized_data = enforce_schema(flattened, accomodation_schema)\n",
        "            documents.append(standardized_data)\n",
        "        path = f'trusted_accomodation/{city}/{file_name}'\n",
        "        with open(path, \"w\") as file:\n",
        "            json.dump(documents, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weather data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Acces the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8470/8470 [00:11<00:00, 705.90it/s]  \n"
          ]
        }
      ],
      "source": [
        "for blob in tqdm(blobs):\n",
        "    if \"weather/\" in blob.name and \"json\" in blob.name:\n",
        "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob.name)\n",
        "        blob_data = blob_client.download_blob()\n",
        "        content = blob_data.readall().decode('utf-8')\n",
        "        data = json.loads(content)\n",
        "        with open(blob.name, \"w\") as file:\n",
        "            json.dump(data, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Standardize timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardized_hours(timestamp):\n",
        "    dt = datetime.fromisoformat(timestamp)\n",
        "    hour_only = dt.strftime(\"%H:%M\")\n",
        "    return hour_only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 94/94 [00:00<00:00, 976.82it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 670.61it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 1242.84it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 1058.38it/s]\n"
          ]
        }
      ],
      "source": [
        "with open(\"weather_schema.json\", \"r\") as file:\n",
        "    weather_schema = json.load(file)\n",
        "\n",
        "cities = ['Barcelona', \"Paris\", 'Rome', 'Madrid']\n",
        "\n",
        "for city in cities:\n",
        "    for file_name in tqdm(os.listdir(f'weather/{city}/')):\n",
        "        \n",
        "        path = f'weather/{city}/{file_name}'\n",
        "        with open(path, \"r\") as file:\n",
        "            data = json.load(file)\n",
        "        \n",
        "        standardized = data['hourly']\n",
        "        standardized['time'] = list(map(standardized_hours, standardized['time']))\n",
        "        schema = get_schema(standardized)\n",
        "        standardized_data = enforce_schema(standardized, weather_schema)\n",
        "        \n",
        "        path = f'trusted_weather/{city}/{file_name}'\n",
        "        with open(path, \"w\") as file:\n",
        "            json.dump(standardized_data, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploitation Zone\n",
        "Create the following data artifacts:\n",
        "In HDFS implement:\n",
        "* Hotel\n",
        "* Sunny_Dates\n",
        "* Rainy_Dates\n",
        "* Cloudy_Dates\n",
        "* Snowy_Dates\n",
        "* Weather_Ranking_Dates\n",
        "* Accomodation_Ranking_Dates\n",
        "\n",
        "In Neo4J implement:\n",
        "* Points of Interest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHQMnHfmq29F"
      },
      "source": [
        "# Transportation\n",
        "\n",
        "Find out more in: https://openrouteservice.org/dev/#/api-docs/optimization/post\n",
        "Alternatives: https://github.com/graphhopper/graphhopper/blob/master/README.md#Map-Matching\n",
        "https://github.com/VROOM-Project/vroom/blob/master/docs/API.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ahJEobq4NU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tpc-di",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
